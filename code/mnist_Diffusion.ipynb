{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8802e8a-7091-4a13-a535-e2031adc8baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9438b-728d-439b-97b8-15f988c625e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "batch_size = 1024\n",
    "image_size = 28\n",
    "timesteps = 1000  # Total diffusion steps\n",
    "\n",
    "# Helper function to compute the linear noise schedule\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "# Define the noise schedule\n",
    "betas = linear_beta_schedule(timesteps)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "\n",
    "# Noise schedule parameters\n",
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu()).reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "    return out\n",
    "\n",
    "# Sampling from a normal distribution for generation\n",
    "def sample_from_model(model, n_samples, image_size, device):\n",
    "    model.eval()\n",
    "    x = torch.randn(n_samples, 1, image_size, image_size).to(device)  # Initialize with random noise\n",
    "    for t in range(timesteps - 1, -1, -1):\n",
    "        t_tensor = torch.full((n_samples,), t, dtype=torch.long, device=device)\n",
    "        predicted_noise = model(x, t_tensor)\n",
    "\n",
    "        beta_t = extract(betas, t_tensor, x.shape)\n",
    "        alpha_t = extract(alphas, t_tensor, x.shape)\n",
    "        alpha_t_cumprod = extract(alphas_cumprod, t_tensor, x.shape)\n",
    "\n",
    "        # If t > 0, calculate the previous alpha cumprod (alpha_{t-1})\n",
    "        if t > 0:\n",
    "            alpha_t_cumprod_prev = extract(alphas_cumprod, t_tensor - 1, x.shape)\n",
    "            mean = (1 / torch.sqrt(alpha_t)) * (x - beta_t / torch.sqrt(1 - alpha_t_cumprod) * predicted_noise)\n",
    "            noise = torch.randn_like(x)\n",
    "            x = mean + torch.sqrt(beta_t) * noise\n",
    "        else:\n",
    "            # At t = 0, there's no need for alpha_{t-1}\n",
    "            mean = (1 / torch.sqrt(alpha_t)) * (x - beta_t / torch.sqrt(1 - alpha_t_cumprod) * predicted_noise)\n",
    "            x = mean\n",
    "    return x\n",
    "\n",
    "# U-Net architecture for noise prediction\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Loss function (simple L2 loss between predicted and actual noise)\n",
    "def diffusion_loss(model, x, t, noise):\n",
    "    predicted_noise = model(x, t)\n",
    "    return F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "# Data Loading\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory = True)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)\n",
    "\n",
    "model = UNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256c1ec-d2ea-40cf-ba4d-559720677c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for step, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        # Sample random timesteps for each image in the batch\n",
    "        t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "        # Sample random noise and corrupt the image\n",
    "        noise = torch.randn_like(images)\n",
    "        alpha_t = extract(alphas_cumprod, t, images.shape)\n",
    "        noisy_images = torch.sqrt(alpha_t) * images + torch.sqrt(1 - alpha_t) * noise\n",
    "\n",
    "        # Compute loss\n",
    "        loss = diffusion_loss(model, noisy_images, t, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062d246-1675-44b7-b87a-3a6204072e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some samples after training\n",
    "n_samples = 16\n",
    "samples = sample_from_model(model, n_samples, image_size, device).detach().cpu().numpy()\n",
    "\n",
    "# Plot the generated samples\n",
    "fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb4a12-5886-4cc6-b583-4bdacf21862c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
